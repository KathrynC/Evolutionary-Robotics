# Evolutionary Robotics

A PyBullet-based platform for designing, simulating, and analyzing quadruped gaits. Built as coursework for Josh Bongard's Evolutionary Robotics class at UVM, extending the [Ludobots](https://www.reddit.com/r/ludobots/) curriculum with telemetry infrastructure, gait optimization, and batch evaluation tools.

## The Robot

A minimal quadruped: a cubic torso with two revolute-jointed legs (back and front). Each joint follows a sine-wave trajectory defined by amplitude, frequency, phase, and offset parameters. The legs move in anti-phase (back at phase 0, front at phase π) to produce a crawling gait.

```
body.urdf — Robot morphology (torso + 2 legs, revolute joints)
brain.nndf — Neural network scaffold (3 sensors → 2 motors)
world.sdf — Environment (ground plane + optional obstacles)
```

These are generated by `generate.py`.

## Quick Start

```bash
# Activate environment
conda activate er

# Generate robot artifacts
python3 generate.py

# Run a simulation (GUI)
python3 simulate.py

# Run headless with telemetry
HEADLESS=1 TELEMETRY=1 python3 simulate.py

# Run with a specific gait variant
GAIT_VARIANT_PATH=gaits/sine_crawl_001.json GAIT_MODE=1 HEADLESS=1 python3 simulate.py
```

## Architecture

```
simulate.py          Entry point — instantiates SIMULATION and calls Run()
simulation.py        Core loop: load world → load robot → step physics → log telemetry
robot.py             Robot controller: loads URDF/NNDF, manages sensors and motors
motor.py             Per-joint sine controller with precomputed or on-the-fly trajectories
sensor.py            Touch sensor logger (one per link)
world.py             Loads ground plane and optional SDF environment
constants.py         Central configuration (all defaults, overridable by env vars)
```

### Control Flow

Each simulation timestep:

1. `robot.Sense(t)` — read touch sensors
2. `robot.Think()` — advance neural network (if present)
3. `robot.Act(t, max_force)` — apply motor commands to joints
4. `p.stepSimulation()` — PyBullet physics step
5. Telemetry logged (if enabled)

In **direct gait drive** mode (`GAIT_MODE=1`), steps 1–3 are bypassed. Joint targets are computed on-the-fly from the sine parameters in the gait variant JSON.

## Gait Parameters

| Parameter | Key (JSON) | Range | Description |
|-----------|-----------|-------|-------------|
| Amplitude | `A` | 0.3–1.8 rad | Joint oscillation range |
| Frequency | `f` | 0.6–5.0 Hz | Oscillation rate |
| Back offset | `O_back` | -0.7–0.7 rad | Back leg resting angle |
| Front offset | `O_front` | -0.7–0.7 rad | Front leg resting angle |
| Back phase | `phi_back` | 0–2π | Back leg phase |
| Front phase | `phi_front` | 0–2π | Front leg phase |
| Max force | `MAX_FORCE` | 80–650 N | Motor torque limit |

Each joint follows: `target = offset + amplitude * sin(2π * frequency * t + phase)`

## Gait Variants

Stored as JSON in `gaits/`:

```json
{
  "name": "Sine Crawl 001",
  "variant_id": "001",
  "type": "sine_2joint",
  "A": 0.5145,
  "f": 2.1371,
  "O_back": 0.7591,
  "O_front": -0.3463,
  "phi_back": 6.234472,
  "phi_front": 1.287714,
  "MAX_FORCE": 2000.0,
  "SIM_STEPS": 2000
}
```

## Telemetry

Enable with `TELEMETRY=1`. Output goes to `artifacts/telemetry/{variant_id}/{run_id}/`.

**Per-step log** (`telemetry.jsonl`):
```json
{"t": 0, "base": {"x": 0.0, "y": 0.0, "z": 1.5}, "rpy": {"r": 0.0, "p": 0.0, "y": 0.0}, "contacts": 8, "joints": [...]}
```

**Run summary** (`summary.json`):
```json
{
  "variant_id": "001",
  "run_id": "run0",
  "steps_logged": 200,
  "max_abs_roll": 0.0024,
  "max_abs_pitch": 0.0007,
  "upright_fraction": 0.99,
  "delta": {"dx": 0.5, "dy": 0.02, "dz": -0.001}
}
```

Key metrics:
- `delta.dx` — forward displacement (meters), the primary fitness measure
- `upright_fraction` — proportion of timesteps the robot stayed upright
- `max_abs_roll`, `max_abs_pitch` — stability indicators

## Tools

### Gait Optimizer

Random search over the sine parameter space:

```bash
python3 optimize_gait.py --trials 800 --seconds 10 --seed 2
```

Scores by horizontal displacement with penalties for flipping.

### Zoo Runner

Batch evaluation of multiple gait variants:

```bash
python3 tools/zoo/run_zoo.py --variants_dir artifacts/rules/zoo --runs 5 --tag experiment_1
```

Iterates over `variant_*.json` files, runs each N times, collects telemetry and summaries.

### Open-Loop Playback

Export and replay precomputed motor trajectories:

```bash
python3 open_loop.py                          # Run open-loop gait
SAVE_VECTORS_ONLY=1 python3 open_loop.py      # Export angles only
python3 render_openloop_frames.py             # Render PNG frames
```

### Analysis

```bash
python3 analyze.py    # Plot touch sensor time series
```

## Environment Variables

All configuration in `constants.py` can be overridden by environment variables.

| Variable | Default | Description |
|----------|---------|-------------|
| `HEADLESS` | 0 | Run without GUI (PyBullet DIRECT mode) |
| `SIM_STEPS` | 4000 | Simulation steps per episode |
| `MAX_FORCE` | 150.0 | Motor force limit (N) |
| `GAIT_MODE` | 0 | 0 = neural/precomputed, 1 = direct sine drive |
| `GAIT_VARIANT_PATH` | — | Path to gait variant JSON |
| `TELEMETRY` | 0 | Enable telemetry logging |
| `TELEMETRY_EVERY` | 10 | Log every N steps |
| `TELEMETRY_OUT` | artifacts/telemetry | Telemetry output root |
| `SIM_DEBUG` | 0 | Verbose startup and exception printing |
| `SLEEP_TIME` | — | Override inter-step sleep (seconds) |
| `FOLLOW_CAMERA` | 0 | Camera follows robot in GUI |
| `USE_NN` | 0 | Use neural network outputs for motor control |

## Physics

- **Engine**: PyBullet, 240 Hz (dt = 1/240 s)
- **Gravity**: -9.8 m/s^2
- **Robot friction**: 2.5 (lateral)
- **Ground friction**: 1.5–2.0 (lateral)
- **Robot mass**: 1 kg per link (torso + 2 legs = 3 kg)

## Directory Structure

```
├── simulate.py              # Entry point
├── simulation.py            # Core simulation loop
├── robot.py                 # Robot controller
├── motor.py                 # Joint sine controller
├── sensor.py                # Touch sensor logger
├── world.py                 # Environment loader
├── constants.py             # Configuration defaults
├── generate.py              # URDF/NNDF/SDF generator
├── optimize_gait.py         # Random search gait optimizer
├── open_loop.py             # Open-loop playback & export
├── analyze.py               # Sensor data plotting
├── body.urdf                # Robot morphology (generated)
├── brain.nndf               # Neural network (generated)
├── world.sdf                # Environment (generated)
├── gaits/                   # Gait variant JSON files
├── pyrosim/                 # Vendored neural sim library
├── tools/
│   ├── telemetry/logger.py  # Telemetry recording
│   └── zoo/run_zoo.py       # Batch gait evaluation
├── artifacts/
│   ├── telemetry/           # Per-run telemetry output
│   └── rules/               # Generated rulesets & scores
├── data/                    # Numpy arrays & rendered frames
└── scripts/                 # Patch application helpers
```

## Origins

Based on the [Ludobots](https://www.reddit.com/r/ludobots/) curriculum (r/ludobots), which teaches evolutionary robotics through incremental PyBullet exercises. This repository extends that foundation with:

- Parameterized sine gait controllers (bypassing the neural network for direct exploration)
- Structured telemetry with per-step and summary logging
- Batch evaluation infrastructure (zoo runner)
- Gait optimization via random search
- Environment variable configuration for headless/scripted execution
